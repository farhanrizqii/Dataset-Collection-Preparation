{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install googletrans==4.0.0-rc1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEZWhuTuJtI6",
        "outputId": "39788701-c9d4-4407-93b7-23eef97e68b0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting googletrans==4.0.0-rc1\n",
            "  Using cached googletrans-4.0.0rc1.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting httpx==0.13.3 (from googletrans==4.0.0-rc1)\n",
            "  Using cached httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.2.2)\n",
            "Collecting hstspreload (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Using cached hstspreload-2024.5.1-py3-none-any.whl (1.1 MB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.1)\n",
            "Collecting chardet==3.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Using cached chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "Collecting idna==2.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Using cached idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "Collecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Using cached rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Using cached httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "Collecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Using cached h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "Collecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Using cached h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "Collecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Using cached hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Using cached hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17395 sha256=42e32ee0a02b1c3de76927ac0f5a4515d3ed1dc2d437f2b19c0c60fe624c297b\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/59/9f/7372f0cf70160fe61b528532e1a7c8498c4becd6bcffb022de\n",
            "Successfully built googletrans\n",
            "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.7\n",
            "    Uninstalling idna-3.7:\n",
            "      Successfully uninstalled idna-3.7\n",
            "Successfully installed chardet-3.0.4 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2024.5.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUGPWTWDr4d3",
        "outputId": "8f15e74d-2d69-4d23-f8ac-581c9d41d3b7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from googletrans import Translator\n",
        "\n",
        "# Fungsi untuk menerjemahkan teks menggunakan Google Translate API\n",
        "def translate_text(text):\n",
        "    translator = Translator()\n",
        "    translation = translator.translate(text, src='en', dest='id')\n",
        "    return translation.text\n",
        "\n",
        "# Baca dataset dari file JSON\n",
        "with open('/content/dataset_conversation.json', 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Menerjemahkan teks dalam dataset\n",
        "translated_intents = []\n",
        "for intent in data['intents']:\n",
        "    translated_patterns = []\n",
        "    for pattern in intent['patterns']:\n",
        "        if pattern:\n",
        "            translated_pattern = translate_text(pattern)\n",
        "            translated_patterns.append(translated_pattern)\n",
        "        else:\n",
        "            translated_patterns.append(None)\n",
        "    translated_responses = []\n",
        "    for response in intent['responses']:\n",
        "        if response:\n",
        "            translated_response = translate_text(response)\n",
        "            translated_responses.append(translated_response)\n",
        "        else:\n",
        "            translated_responses.append(None)\n",
        "    translated_intents.append({\n",
        "        'tag': intent['tag'],\n",
        "        'patterns': translated_patterns,\n",
        "        'responses': translated_responses\n",
        "    })\n",
        "\n",
        "# Simpan dataset yang telah diterjemahkan ke dalam file JSON\n",
        "translated_data = {'intents': translated_intents}\n",
        "with open('dataset_percakapan.json', 'w') as file:\n",
        "    json.dump(translated_data, file, ensure_ascii=False, indent=4)\n"
      ],
      "metadata": {
        "id": "TVUnsXuAZcj3"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}